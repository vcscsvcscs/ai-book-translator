# Configuration file for LLM providers

# OpenAI Configuration
openai:
  api_key: "YOUR_OPENAI_API_KEY"
  model: "gpt-4o"  # Options: gpt-4o, gpt-4o-mini, gpt-3.5-turbo, etc.

# Azure OpenAI Configuration
azure:
  api_key: "YOUR_AZURE_OPENAI_API_KEY"
  endpoint: "https://your-resource-name.openai.azure.com/"
  api_version: "2024-02-01"
  deployment_name: "your-deployment-name"  # The name of your deployed model

# Google Gemini Configuration
gemini:
  api_key: "YOUR_GEMINI_API_KEY"
  model: "gemini-2.5-flash-preview-05-20"  # Options: gemini-1.5-flash, gemini-1.5-pro, etc.

# Ollama Configuration (for local models)
ollama:
  model: "llama3.1"  # Options: llama3.1, mistral, codellama, etc.
  base_url: "http://localhost:11434"  # Default Ollama server URL